{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "461447e8",
   "metadata": {},
   "source": [
    "Voici un résumé des différentes méthodes d’optimisation stochastique présentées dans les notebooks **Random Search**, **Simulated Annealing** et **Evolutionary Strategies** :\n",
    "\n",
    "---\n",
    "\n",
    "## 1. **Random Search (Recherche Aléatoire Pure)**\n",
    "- **Principe** : On échantillonne aléatoirement des points dans l’espace de recherche, selon une distribution uniforme, et on garde le meilleur trouvé.\n",
    "- **Avantages** : Simple, ne nécessite aucune information sur la dérivée ou la structure du problème.\n",
    "- **Inconvénients** : Inefficace dans les espaces de grande dimension, ne tient pas compte des résultats précédents pour guider la recherche.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **Random Optimization (Optimisation Aléatoire Locale)**\n",
    "- **Principe** : À chaque itération, on perturbe légèrement la solution courante (par exemple, en ajoutant un bruit gaussien), et on accepte la nouvelle solution si elle est meilleure.\n",
    "- **Avantages** : Plus efficace que la recherche pure, car la recherche est locale autour des bons points.\n",
    "- **Inconvénients** : Risque de rester bloqué dans un minimum local.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **Simulated Annealing (Recuit Simulé)**\n",
    "- **Principe** : Variante de l’optimisation aléatoire qui accepte parfois des solutions moins bonnes, selon une probabilité qui décroît avec le temps (température).\n",
    "- **Mécanisme** :  \n",
    "  - Si la nouvelle solution est meilleure, on l’accepte.\n",
    "  - Si elle est moins bonne, on l’accepte avec une probabilité $ \\exp\\left(-\\frac{f(x')-f(x)}{T}\\right) $, où $T$ (température) décroît au fil des itérations.\n",
    "- **Avantages** : Permet d’échapper aux minima locaux, exploration/exploitation contrôlée par la température.\n",
    "- **Inconvénients** : Nécessite de bien choisir la décroissance de la température.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. **Evolutionary Strategies (Stratégies Évolutionnaires)**\n",
    "- **Principe général** : Inspiré de l’évolution naturelle, on fait évoluer une population de solutions par mutation (ajout de bruit), sélection et recombinaison.\n",
    "- **(1+λ) ES** :  \n",
    "  - À chaque génération, on génère λ descendants autour du parent courant.\n",
    "  - On garde le meilleur pour la génération suivante.\n",
    "- **(μ,λ) ES** :  \n",
    "  - On génère λ descendants à partir de μ parents.\n",
    "  - Seuls les meilleurs descendants deviennent parents.\n",
    "- **Canonical ES** :  \n",
    "  - Utilise un classement des individus et une moyenne pondérée des meilleurs pour guider la recherche.\n",
    "- **CMA-ES (Covariance Matrix Adaptation ES)** :  \n",
    "  - Adapte la forme et la taille de la distribution de mutation (covariance) en fonction des solutions trouvées.\n",
    "  - Très performant pour les problèmes continus complexes.\n",
    "\n",
    "---\n",
    "\n",
    "## **Comparaison et Points Clés**\n",
    "- **Random Search** : Basique, peu efficace sauf pour petits espaces.\n",
    "- **Random Optimization** : Ajoute une notion de voisinage, mais reste local.\n",
    "- **Simulated Annealing** : Ajoute la possibilité de sortir des minima locaux grâce à l’acceptation probabiliste.\n",
    "- **Evolutionary Strategies** :  \n",
    "  - Exploitent une population, donc plus robustes.\n",
    "  - Les versions avancées (Canonical, CMA-ES) adaptent dynamiquement la recherche et sont très efficaces pour l’optimisation sans gradient.\n",
    "\n",
    "---\n",
    "\n",
    "**Résumé visuel** :\n",
    "\n",
    "| Méthode                | Exploite le passé ? | Population | Adaptation | Sort des minima locaux ? |\n",
    "|------------------------|:------------------:|:----------:|:----------:|:------------------------:|\n",
    "| Random Search          | Non                | Non        | Non        | Non                     |\n",
    "| Random Optimization    | Oui (local)        | Non        | Non        | Non                     |\n",
    "| Simulated Annealing    | Oui (local)        | Non        | Température| Oui                     |\n",
    "| Evolutionary Strategies| Oui                | Oui        | Oui        | Oui                     |\n",
    "\n",
    "---\n",
    "\n",
    "Chaque méthode a ses avantages selon la nature du problème (dimension, présence de minima locaux, coût d’évaluation, etc.)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
